{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObFHJxyXM6rV0RgbVEfnWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wsGit7/Invest/blob/main/pdfHighlight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFThAi0WO_NY",
        "outputId": "fe91a90a-724d-45d9-a2ea-5c4b3f658c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# super\n",
        "import os\n",
        "import re\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def normalize_word(w):\n",
        "    \"\"\"\n",
        "    Lowercase the word and remove punctuation from the beginning and end.\n",
        "    \"\"\"\n",
        "    return re.sub(r'^\\W+|\\W+$', '', w.lower())\n",
        "\n",
        "# --- Read the target sequences (each line is a full phrase) ---\n",
        "with open(\"unikalneWyr.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    # Each non-empty line is a target phrase (sequence of words)\n",
        "    target_lines = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# Convert each target phrase into a list of normalized words.\n",
        "target_sequences = []\n",
        "for line in target_lines:\n",
        "    words = line.split()  # split on whitespace\n",
        "    normalized = [normalize_word(word) for word in words]\n",
        "    target_sequences.append(normalized)\n",
        "\n",
        "# --- Folder containing the PDF files ---\n",
        "folder = \"jurek\"\n",
        "\n",
        "# Process each PDF file in the folder.\n",
        "for filename in os.listdir(folder):\n",
        "    if not filename.lower().endswith(\".pdf\"):\n",
        "        continue\n",
        "\n",
        "    filepath = os.path.join(folder, filename)\n",
        "    print(f\"Processing {filepath}...\")\n",
        "    doc = fitz.open(filepath)\n",
        "\n",
        "    for page in doc:\n",
        "        # Get words from the page.\n",
        "        # Each element is a tuple:\n",
        "        # (x0, y0, x1, y1, word, block_no, line_no, word_no)\n",
        "        page_words = page.get_text(\"words\")\n",
        "        # Create a list of (normalized_word, bounding_box) for each word.\n",
        "        normalized_words = []\n",
        "        for winfo in page_words:\n",
        "            word_text = winfo[4]\n",
        "            norm = normalize_word(word_text)\n",
        "            bbox = fitz.Rect(winfo[0], winfo[1], winfo[2], winfo[3])\n",
        "            normalized_words.append((norm, bbox))\n",
        "\n",
        "        # For each target sequence, try to find a contiguous match in the page's words.\n",
        "        for target_seq in target_sequences:\n",
        "            t_len = len(target_seq)\n",
        "            if t_len == 0:\n",
        "                continue\n",
        "\n",
        "            # Loop over positions in the normalized_words list.\n",
        "            i = 0\n",
        "            while i <= len(normalized_words) - t_len:\n",
        "                match_found = True\n",
        "                # Check sequentially if the target matches\n",
        "                for j in range(t_len):\n",
        "                    if normalized_words[i+j][0] != target_seq[j]:\n",
        "                        match_found = False\n",
        "                        break\n",
        "                if match_found:\n",
        "                    # Combine bounding boxes for the sequence.\n",
        "                    rects = [normalized_words[i+j][1] for j in range(t_len)]\n",
        "                    combined_rect = rects[0]\n",
        "                    for r in rects[1:]:\n",
        "                        combined_rect |= r  # union of rectangles\n",
        "                    # Highlight the found sequence (yellow highlight).\n",
        "                    annot = page.add_highlight_annot(combined_rect)\n",
        "                    annot.set_colors(stroke=(1, 1, 0))  # Yellow: RGB (1,1,0)\n",
        "                    annot.update()\n",
        "                    # Advance the index to skip over this found sequence to avoid overlapping matches.\n",
        "                    i += t_len\n",
        "                else:\n",
        "                    i += 1\n",
        "\n",
        "    # Save the modified PDF with a new name.\n",
        "    new_filepath = os.path.join(folder, \"highlighted_\" + filename)\n",
        "    doc.save(new_filepath, garbage=4, deflate=True, clean=True)\n",
        "    doc.close()\n",
        "    print(f\"Saved highlighted version as: {new_filepath}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND_Kcs1GkVaj",
        "outputId": "447d1ab6-8126-4903-d331-017cf410ab6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing jurek/ustawaSluzbieZagrani.pdf...\n",
            "Saved highlighted version as: jurek/highlighted_ustawaSluzbieZagrani.pdf\n"
          ]
        }
      ]
    }
  ]
}